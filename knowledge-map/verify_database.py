#!/usr/bin/env python3
"""
æ•°æ®åº“éªŒè¯è„šæœ¬
éªŒè¯æ‰€æœ‰æ•°æ®åº“è¿æ¥å’ŒåŠŸèƒ½
"""
import asyncio
import sys
import os
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from loguru import logger
from sqlalchemy import text
from database.connection import db_manager
from services.cache import cache_service, session_service, metrics_service


async def test_postgresql():
    """æµ‹è¯•PostgreSQLåŠŸèƒ½"""
    logger.info("ğŸ§ª æµ‹è¯•PostgreSQLåŠŸèƒ½...")
    
    try:
        async with db_manager.get_postgres_session() as session:
            # æµ‹è¯•åŸºæœ¬æŸ¥è¯¢
            result = await session.execute(text("SELECT 1 as test"))
            assert result.scalar() == 1
            logger.info("âœ… PostgreSQLåŸºæœ¬æŸ¥è¯¢æµ‹è¯•é€šè¿‡")
            
            # æµ‹è¯•pgvector
            await session.execute(text("SELECT '[1,2,3]'::vector"))
            logger.info("âœ… pgvectoræ‰©å±•æµ‹è¯•é€šè¿‡")
            
            # æµ‹è¯•è¡¨å­˜åœ¨æ€§
            result = await session.execute(text("""
                SELECT table_name FROM information_schema.tables 
                WHERE table_schema = 'public' AND table_name = 'document_vectors'
            """))
            if result.scalar():
                logger.info("âœ… document_vectorsè¡¨å­˜åœ¨")
            else:
                logger.warning("âš ï¸ document_vectorsè¡¨ä¸å­˜åœ¨")
            
            # æµ‹è¯•å‘é‡ç›¸ä¼¼åº¦è®¡ç®—
            await session.execute(text("""
                SELECT '[1,2,3]'::vector <-> '[1,2,4]'::vector as distance
            """))
            logger.info("âœ… å‘é‡è·ç¦»è®¡ç®—æµ‹è¯•é€šè¿‡")
            
    except Exception as e:
        logger.error(f"âŒ PostgreSQLæµ‹è¯•å¤±è´¥: {e}")
        raise


async def test_neo4j():
    """æµ‹è¯•Neo4jåŠŸèƒ½"""
    logger.info("ğŸ§ª æµ‹è¯•Neo4jåŠŸèƒ½...")
    
    try:
        with db_manager.get_neo4j_session() as session:
            # æµ‹è¯•åŸºæœ¬æŸ¥è¯¢
            result = session.run("RETURN 1 as test")
            record = result.single()
            assert record["test"] == 1
            logger.info("âœ… Neo4jåŸºæœ¬æŸ¥è¯¢æµ‹è¯•é€šè¿‡")
            
            # æµ‹è¯•åˆ›å»ºå’Œåˆ é™¤èŠ‚ç‚¹
            session.run("CREATE (t:Test {name: 'test_node', created: $created})", 
                       created=datetime.now().isoformat())
            logger.info("âœ… Neo4jèŠ‚ç‚¹åˆ›å»ºæµ‹è¯•é€šè¿‡")
            
            # æµ‹è¯•æŸ¥è¯¢èŠ‚ç‚¹
            result = session.run("MATCH (t:Test {name: 'test_node'}) RETURN t")
            record = result.single()
            assert record is not None
            logger.info("âœ… Neo4jèŠ‚ç‚¹æŸ¥è¯¢æµ‹è¯•é€šè¿‡")
            
            # æµ‹è¯•å…³ç³»åˆ›å»º
            session.run("""
                MATCH (t:Test {name: 'test_node'})
                CREATE (t)-[:TESTED_BY]->(:TestResult {status: 'success'})
            """)
            logger.info("âœ… Neo4jå…³ç³»åˆ›å»ºæµ‹è¯•é€šè¿‡")
            
            # æ¸…ç†æµ‹è¯•æ•°æ®
            session.run("MATCH (t:Test {name: 'test_node'}) DETACH DELETE t")
            session.run("MATCH (tr:TestResult {status: 'success'}) DELETE tr")
            logger.info("âœ… Neo4jæµ‹è¯•æ•°æ®æ¸…ç†å®Œæˆ")
            
    except Exception as e:
        logger.error(f"âŒ Neo4jæµ‹è¯•å¤±è´¥: {e}")
        raise


async def test_redis():
    """æµ‹è¯•RedisåŠŸèƒ½"""
    logger.info("ğŸ§ª æµ‹è¯•RedisåŠŸèƒ½...")
    
    try:
        redis_client = await db_manager.get_redis_client()
        
        # æµ‹è¯•åŸºæœ¬æ“ä½œ
        await redis_client.set("test_key", "test_value")
        value = await redis_client.get("test_key")
        assert value.decode() == "test_value"
        logger.info("âœ… RedisåŸºæœ¬æ“ä½œæµ‹è¯•é€šè¿‡")
        
        # æµ‹è¯•TTL
        await redis_client.setex("ttl_test", 1, "will_expire")
        exists_before = await redis_client.exists("ttl_test")
        await asyncio.sleep(1.1)
        exists_after = await redis_client.exists("ttl_test")
        assert exists_before and not exists_after
        logger.info("âœ… Redis TTLæµ‹è¯•é€šè¿‡")
        
        # æµ‹è¯•åˆ—è¡¨æ“ä½œ
        await redis_client.lpush("test_list", "item1", "item2", "item3")
        length = await redis_client.llen("test_list")
        assert length == 3
        logger.info("âœ… Redisåˆ—è¡¨æ“ä½œæµ‹è¯•é€šè¿‡")
        
        # æ¸…ç†æµ‹è¯•æ•°æ®
        await redis_client.delete("test_key", "test_list")
        
        await redis_client.close()
        logger.info("âœ… Redisè¿æ¥æ­£å¸¸å…³é—­")
        
    except Exception as e:
        logger.error(f"âŒ Redisæµ‹è¯•å¤±è´¥: {e}")
        raise


async def test_cache_service():
    """æµ‹è¯•ç¼“å­˜æœåŠ¡"""
    logger.info("ğŸ§ª æµ‹è¯•ç¼“å­˜æœåŠ¡...")
    
    try:
        # æµ‹è¯•åŸºæœ¬ç¼“å­˜æ“ä½œ
        test_key = "cache_test_key"
        test_value = {"message": "hello", "timestamp": datetime.now().isoformat()}
        
        # è®¾ç½®ç¼“å­˜
        success = await cache_service.set(test_key, test_value, ttl=60)
        assert success
        logger.info("âœ… ç¼“å­˜è®¾ç½®æµ‹è¯•é€šè¿‡")
        
        # è·å–ç¼“å­˜
        cached_value = await cache_service.get(test_key)
        assert cached_value == test_value
        logger.info("âœ… ç¼“å­˜è·å–æµ‹è¯•é€šè¿‡")
        
        # æ£€æŸ¥å­˜åœ¨æ€§
        exists = await cache_service.exists(test_key)
        assert exists
        logger.info("âœ… ç¼“å­˜å­˜åœ¨æ€§æ£€æŸ¥æµ‹è¯•é€šè¿‡")
        
        # åˆ é™¤ç¼“å­˜
        deleted = await cache_service.delete(test_key)
        assert deleted
        logger.info("âœ… ç¼“å­˜åˆ é™¤æµ‹è¯•é€šè¿‡")
        
        # æµ‹è¯•æœç´¢ç¼“å­˜
        search_results = [{"doc": "test1"}, {"doc": "test2"}]
        await cache_service.set_search_cache(
            "test query", 
            "vector", 
            {"top_k": 5}, 
            search_results
        )
        
        cached_results = await cache_service.get_search_cache(
            "test query",
            "vector",
            {"top_k": 5}
        )
        assert cached_results == search_results
        logger.info("âœ… æœç´¢ç¼“å­˜æµ‹è¯•é€šè¿‡")
        
        # æ¸…ç†æœç´¢ç¼“å­˜
        cleared = await cache_service.clear_search_cache()
        logger.info(f"âœ… æœç´¢ç¼“å­˜æ¸…ç†å®Œæˆï¼Œæ¸…ç†äº† {cleared} ä¸ªé”®")
        
    except Exception as e:
        logger.error(f"âŒ ç¼“å­˜æœåŠ¡æµ‹è¯•å¤±è´¥: {e}")
        raise


async def test_session_service():
    """æµ‹è¯•ä¼šè¯æœåŠ¡"""
    logger.info("ğŸ§ª æµ‹è¯•ä¼šè¯æœåŠ¡...")
    
    try:
        session_id = "test_session_123"
        user_data = {"user_id": "user123", "role": "admin"}
        
        # åˆ›å»ºä¼šè¯
        success = await session_service.create_session(session_id, user_data)
        assert success
        logger.info("âœ… ä¼šè¯åˆ›å»ºæµ‹è¯•é€šè¿‡")
        
        # è·å–ä¼šè¯
        session_data = await session_service.get_session(session_id)
        assert session_data is not None
        assert session_data["user_data"] == user_data
        logger.info("âœ… ä¼šè¯è·å–æµ‹è¯•é€šè¿‡")
        
        # æ›´æ–°ä¼šè¯
        update_data = {"last_action": "login"}
        success = await session_service.update_session(session_id, update_data)
        assert success
        logger.info("âœ… ä¼šè¯æ›´æ–°æµ‹è¯•é€šè¿‡")
        
        # éªŒè¯æ›´æ–°
        updated_session = await session_service.get_session(session_id)
        assert "last_action" in updated_session["user_data"]
        assert updated_session["user_data"]["last_action"] == "login"
        logger.info("âœ… ä¼šè¯æ›´æ–°éªŒè¯é€šè¿‡")
        
        # åˆ é™¤ä¼šè¯
        deleted = await session_service.delete_session(session_id)
        assert deleted
        logger.info("âœ… ä¼šè¯åˆ é™¤æµ‹è¯•é€šè¿‡")
        
        # éªŒè¯åˆ é™¤
        deleted_session = await session_service.get_session(session_id)
        assert deleted_session is None
        logger.info("âœ… ä¼šè¯åˆ é™¤éªŒè¯é€šè¿‡")
        
    except Exception as e:
        logger.error(f"âŒ ä¼šè¯æœåŠ¡æµ‹è¯•å¤±è´¥: {e}")
        raise


async def test_metrics_service():
    """æµ‹è¯•æŒ‡æ ‡æœåŠ¡"""
    logger.info("ğŸ§ª æµ‹è¯•æŒ‡æ ‡æœåŠ¡...")
    
    try:
        metric_name = "test_metric"
        
        # æµ‹è¯•è®¡æ•°å™¨
        await metrics_service.increment_counter(metric_name, 5)
        count = await metrics_service.get_counter(metric_name)
        assert count == 5
        logger.info("âœ… æŒ‡æ ‡è®¡æ•°å™¨æµ‹è¯•é€šè¿‡")
        
        # æµ‹è¯•æ—¶é—´è®°å½•
        timing_metric = "test_timing"
        durations = [100, 200, 150, 300, 250]
        
        for duration in durations:
            await metrics_service.record_timing(timing_metric, duration)
        
        stats = await metrics_service.get_timing_stats(timing_metric)
        assert stats["count"] == 5
        assert stats["avg"] == 200.0
        assert stats["min"] == 100
        assert stats["max"] == 300
        logger.info("âœ… æŒ‡æ ‡æ—¶é—´è®°å½•æµ‹è¯•é€šè¿‡")
        
    except Exception as e:
        logger.error(f"âŒ æŒ‡æ ‡æœåŠ¡æµ‹è¯•å¤±è´¥: {e}")
        raise


async def test_integration():
    """é›†æˆæµ‹è¯•"""
    logger.info("ğŸ§ª æ‰§è¡Œé›†æˆæµ‹è¯•...")
    
    try:
        # æ¨¡æ‹Ÿå®Œæ•´çš„æ•°æ®æµç¨‹
        
        # 1. åœ¨PostgreSQLä¸­å­˜å‚¨æ–‡æ¡£å‘é‡
        async with db_manager.get_postgres_session() as session:
            from database.models import DocumentVector
            import numpy as np
            
            test_doc = DocumentVector(
                document_id="integration_test_doc",
                content="è¿™æ˜¯ä¸€ä¸ªé›†æˆæµ‹è¯•æ–‡æ¡£",
                content_hash="integration_test_hash",
                embedding=np.random.rand(768).tolist(),
                metadata={"test": "integration"},
                source="integration_test",
                source_type="test"
            )
            
            session.add(test_doc)
            await session.commit()
            doc_id = test_doc.id
            logger.info("âœ… PostgreSQLæ–‡æ¡£å­˜å‚¨æµ‹è¯•é€šè¿‡")
        
        # 2. åœ¨Neo4jä¸­åˆ›å»ºå¯¹åº”çš„å›¾è°±èŠ‚ç‚¹
        with db_manager.get_neo4j_session() as session:
            session.run("""
                CREATE (d:Document {
                    id: $doc_id,
                    content: $content,
                    source: $source
                })
                CREATE (k:Keyword {word: 'é›†æˆæµ‹è¯•'})
                CREATE (d)-[:CONTAINS_KEYWORD]->(k)
            """, doc_id=str(doc_id), content="è¿™æ˜¯ä¸€ä¸ªé›†æˆæµ‹è¯•æ–‡æ¡£", source="integration_test")
            logger.info("âœ… Neo4jå›¾è°±èŠ‚ç‚¹åˆ›å»ºæµ‹è¯•é€šè¿‡")
        
        # 3. ç¼“å­˜æŸ¥è¯¢ç»“æœ
        search_result = [{"id": str(doc_id), "score": 0.95}]
        await cache_service.set_search_cache(
            "é›†æˆæµ‹è¯•", 
            "integration", 
            {"doc_id": str(doc_id)}, 
            search_result
        )
        logger.info("âœ… ç¼“å­˜æŸ¥è¯¢ç»“æœæµ‹è¯•é€šè¿‡")
        
        # 4. è®°å½•æŒ‡æ ‡
        await metrics_service.increment_counter("integration_test_queries")
        await metrics_service.record_timing("integration_test_duration", 150)
        logger.info("âœ… æŒ‡æ ‡è®°å½•æµ‹è¯•é€šè¿‡")
        
        # 5. éªŒè¯æ•°æ®ä¸€è‡´æ€§
        # PostgreSQLæŸ¥è¯¢
        async with db_manager.get_postgres_session() as session:
            result = await session.execute(text(
                "SELECT COUNT(*) FROM document_vectors WHERE document_id = :doc_id"
            ), {"doc_id": "integration_test_doc"})
            pg_count = result.scalar()
            assert pg_count == 1
        
        # Neo4jæŸ¥è¯¢
        with db_manager.get_neo4j_session() as session:
            result = session.run(
                "MATCH (d:Document {id: $doc_id}) RETURN count(d) as count", 
                doc_id=str(doc_id)
            )
            neo4j_count = result.single()["count"]
            assert neo4j_count == 1
        
        # ç¼“å­˜æŸ¥è¯¢
        cached_result = await cache_service.get_search_cache(
            "é›†æˆæµ‹è¯•", 
            "integration", 
            {"doc_id": str(doc_id)}
        )
        assert cached_result == search_result
        
        logger.info("âœ… æ•°æ®ä¸€è‡´æ€§éªŒè¯é€šè¿‡")
        
        # æ¸…ç†æµ‹è¯•æ•°æ®
        async with db_manager.get_postgres_session() as session:
            await session.execute(text(
                "DELETE FROM document_vectors WHERE document_id = :doc_id"
            ), {"doc_id": "integration_test_doc"})
            await session.commit()
        
        with db_manager.get_neo4j_session() as session:
            session.run("MATCH (d:Document {id: $doc_id}) DETACH DELETE d", doc_id=str(doc_id))
            session.run("MATCH (k:Keyword {word: 'é›†æˆæµ‹è¯•'}) DELETE k")
        
        await cache_service.clear_search_cache()
        
        logger.info("âœ… é›†æˆæµ‹è¯•æ•°æ®æ¸…ç†å®Œæˆ")
        logger.info("ğŸ‰ é›†æˆæµ‹è¯•å…¨éƒ¨é€šè¿‡ï¼")
        
    except Exception as e:
        logger.error(f"âŒ é›†æˆæµ‹è¯•å¤±è´¥: {e}")
        raise


async def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="æ•°æ®åº“éªŒè¯è„šæœ¬")
    parser.add_argument("--quick", action="store_true", help="å¿«é€ŸéªŒè¯ï¼Œè·³è¿‡é›†æˆæµ‹è¯•")
    args = parser.parse_args()
    
    logger.info("ğŸš€ å¼€å§‹æ•°æ®åº“éªŒè¯...")
    
    try:
        # åˆå§‹åŒ–æ•°æ®åº“è¿æ¥
        await db_manager.initialize()
        
        # åŸºç¡€æ•°æ®åº“æµ‹è¯•
        await test_postgresql()
        await test_neo4j()
        await test_redis()
        
        # æœåŠ¡å±‚æµ‹è¯•
        await test_cache_service()
        await test_session_service()
        await test_metrics_service()
        
        # é›†æˆæµ‹è¯• (é™¤éæŒ‡å®šè·³è¿‡)
        if not args.quick:
            await test_integration()
        
        logger.info("ğŸ‰ æ‰€æœ‰æ•°æ®åº“éªŒè¯æµ‹è¯•é€šè¿‡ï¼")
        logger.info("âœ¨ ç³»ç»Ÿå·²å‡†å¤‡å°±ç»ªï¼Œå¯ä»¥å¼€å§‹ä½¿ç”¨")
        
    except Exception as e:
        logger.error(f"âŒ æ•°æ®åº“éªŒè¯å¤±è´¥: {e}")
        sys.exit(1)
        
    finally:
        await db_manager.close()


if __name__ == "__main__":
    asyncio.run(main())