"""
çŸ¥è¯†å›¾è°±ç³»ç»Ÿ REST API æœåŠ¡å™¨ - ç®€åŒ–ç‰ˆ
åŸºäºé‡æ„åçš„ç»„ä»¶æ¶æ„
"""

import asyncio
import uuid
import os
import sys
from typing import Dict, List, Optional, Any
from fastapi import FastAPI, HTTPException, BackgroundTasks, File, UploadFile, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel, Field
import uvicorn
from datetime import datetime
import tempfile
import shutil

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from config import get_default_config
from core.factory import get_factory

# è¯·æ±‚/å“åº”æ¨¡å‹
class SearchRequest(BaseModel):
    query: str = Field(..., description="æœç´¢æŸ¥è¯¢æ–‡æœ¬")
    top_k: int = Field(10, description="è¿”å›ç»“æœæ•°é‡", ge=1, le=100)
    file_type: Optional[str] = Field("all", description="æ–‡ä»¶ç±»å‹è¿‡æ»¤: 'code', 'document', 'all'")

class SearchResult(BaseModel):
    content: str
    metadata: Dict[str, Any]
    similarity: float

class SearchResponse(BaseModel):
    query: str
    results: List[SearchResult]
    total_results: int

class SystemStatus(BaseModel):
    document_count: int
    vector_dimension: int
    graph_nodes: int
    graph_edges: int
    supported_extensions: List[str]
    available_components: Dict[str, List[str]]

class AddTextRequest(BaseModel):
    content: str = Field(..., description="æ–‡æœ¬å†…å®¹")
    title: str = Field("", description="æ–‡æ¡£æ ‡é¢˜")
    save_graph: bool = Field(True, description="æ˜¯å¦ä¿å­˜åˆ°çŸ¥è¯†å›¾è°±")

class ProcessingStatus(BaseModel):
    status: str  # 'processing', 'completed', 'failed'
    message: str
    progress: int
    result: Optional[Any] = None
    error: Optional[str] = None

class UploadResponse(BaseModel):
    task_id: str

class ApiResponse(BaseModel):
    success: bool
    message: str
    data: Optional[Any] = None
    error: Optional[str] = None

# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="çŸ¥è¯†å›¾è°±ç³»ç»Ÿ API",
    description="æä¾›æ–‡æ¡£å¤„ç†ã€çŸ¥è¯†æœç´¢ã€å›¾ç»“æ„åˆ†æç­‰åŠŸèƒ½",
    version="1.0.0"
)

# é…ç½®CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://127.0.0.1:3000", "http://localhost:3001", "http://127.0.0.1:3001"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# å…¨å±€å˜é‡
factory = None
vector_store = None
knowledge_graph = None
processing_tasks: Dict[str, ProcessingStatus] = {}

@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨æ—¶åˆå§‹åŒ–"""
    global factory, vector_store, knowledge_graph
    try:
        # è·å–é…ç½®
        config = get_default_config()
        
        # åˆ›å»ºå·¥å‚
        factory = get_factory(config)
        
        # åˆ›å»ºç»„ä»¶
        vector_store = factory.create_vector_store()
        knowledge_graph = factory.create_knowledge_graph()
        
        # é…ç½®å‘é‡å­˜å‚¨çš„embedding_provider
        embedding_provider = factory.create_embedding_provider()
        vector_store.configure(embedding_provider=embedding_provider)
        
        # åŠ è½½åˆå¹¶åçš„çŸ¥è¯†å›¾è°±
        merged_graph_path = "data/graphs/merged_graph.pkl"
        if os.path.exists(merged_graph_path):
            knowledge_graph.load_graph(merged_graph_path)
            print(f"âœ… å·²åŠ è½½çŸ¥è¯†å›¾è°±: {knowledge_graph.graph.number_of_nodes()} ä¸ªèŠ‚ç‚¹, {knowledge_graph.graph.number_of_edges()} æ¡è¾¹")
        else:
            print("âš ï¸ æœªæ‰¾åˆ°åˆå¹¶çš„çŸ¥è¯†å›¾è°±æ–‡ä»¶")
        
        # æ˜¾ç¤ºä»£ç è§£æå™¨æ”¯æŒä¿¡æ¯
        from implementations.parsers.code_parser_factory import code_parser_factory
        supported_code_exts = code_parser_factory.get_supported_extensions()
        supported_languages = code_parser_factory.get_supported_languages()
        print(f"âœ… ä»£ç è§£æå™¨å·²å°±ç»ª: æ”¯æŒ {len(supported_languages)} ç§è¯­è¨€ {supported_languages}")
        print(f"   æ”¯æŒçš„ä»£ç æ–‡ä»¶æ ¼å¼: {supported_code_exts}")
        
        print("âœ… çŸ¥è¯†å›¾è°±ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    except Exception as e:
        print(f"âŒ ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
        raise

@app.get("/api/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "service": "knowledge-graph-api"
    }

@app.get("/api/status", response_model=ApiResponse)
async def get_system_status():
    """è·å–ç³»ç»ŸçŠ¶æ€"""
    try:
        if vector_store is None or knowledge_graph is None:
            raise HTTPException(status_code=500, detail="ç³»ç»Ÿæœªåˆå§‹åŒ–")
        
        # è·å–åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
        doc_count = len(getattr(vector_store, 'documents', []))
        vector_dim = getattr(vector_store, 'dimension', 384)  # é»˜è®¤dimension
        
        # è·å–å›¾ç»“æ„ç»Ÿè®¡
        graph_nodes = len(getattr(knowledge_graph, 'nodes', []))
        graph_edges = len(getattr(knowledge_graph, 'edges', []))
        
        # è·å–æ”¯æŒçš„æ–‡ä»¶æ ¼å¼
        supported_exts = ['.txt', '.md', '.pdf', '.docx']
        
        # è·å–å¯ç”¨ç»„ä»¶
        available_components = {
            'parsers': ['DefaultParser'],
            'embeddings': ['LocalEmbedding'],
            'vector_stores': ['LocalVectorStore'],
            'knowledge_graphs': ['LocalKnowledgeGraph']
        }
        
        status = SystemStatus(
            document_count=doc_count,
            vector_dimension=vector_dim,
            graph_nodes=graph_nodes,
            graph_edges=graph_edges,
            supported_extensions=supported_exts,
            available_components=available_components
        )
        
        return ApiResponse(
            success=True,
            message="ç³»ç»ŸçŠ¶æ€è·å–æˆåŠŸ",
            data=status.dict()
        )
        
    except Exception as e:
        print(f"è·å–ç³»ç»ŸçŠ¶æ€å¤±è´¥: {e}")
        return ApiResponse(
            success=False,
            message="è·å–ç³»ç»ŸçŠ¶æ€å¤±è´¥",
            error=str(e)
        )

@app.post("/api/search", response_model=ApiResponse)
async def search_knowledge(request: SearchRequest):
    """æœç´¢çŸ¥è¯†åº“"""
    try:
        if vector_store is None:
            raise HTTPException(status_code=500, detail="å‘é‡å­˜å‚¨æœªåˆå§‹åŒ–")
        
        # æ„å»ºè¿‡æ»¤æ¡ä»¶
        filter_dict = None
        if request.file_type and request.file_type != "all":
            filter_dict = {"file_type": request.file_type}
        
        # æ‰§è¡Œæœç´¢
        results = vector_store.similarity_search(
            request.query, 
            k=request.top_k * 2,  # è·å–æ›´å¤šç»“æœä»¥ä¾¿è¿‡æ»¤
            filter_dict=filter_dict
        )
        
        # è½¬æ¢ç»“æœæ ¼å¼
        search_results = []
        for doc, similarity in results:
            # å¦‚æœæ²¡æœ‰ä½¿ç”¨filter_dictï¼Œéœ€è¦åœ¨è¿™é‡Œè¿›è¡Œåå¤„ç†è¿‡æ»¤
            if request.file_type != "all" and filter_dict is None:
                # åŸºäºsource_fileæˆ–å…¶ä»–metadataè¿›è¡Œè¿‡æ»¤
                source_file = doc.metadata.get("source_file", "")
                if request.file_type == "code":
                    if not any(source_file.endswith(ext) for ext in ['.go', '.py', '.js', '.ts', '.java', '.cpp', '.c', '.mod', '.sum']):
                        continue
                elif request.file_type == "document":
                    if any(source_file.endswith(ext) for ext in ['.go', '.py', '.js', '.ts', '.java', '.cpp', '.c']):
                        continue
            
            search_results.append(SearchResult(
                content=doc.page_content,
                metadata=doc.metadata,
                similarity=float(similarity)
            ))
            
            # é™åˆ¶æœ€ç»ˆç»“æœæ•°é‡
            if len(search_results) >= request.top_k:
                break
        
        response = SearchResponse(
            query=request.query,
            results=search_results,
            total_results=len(search_results)
        )
        
        return ApiResponse(
            success=True,
            message=f"æœç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(search_results)} ä¸ªç»“æœ",
            data=response.dict()
        )
        
    except Exception as e:
        print(f"æœç´¢å¤±è´¥: {e}")
        return ApiResponse(
            success=False,
            message="æœç´¢å¤±è´¥",
            error=str(e)
        )

@app.get("/api/components", response_model=ApiResponse)
async def get_available_components():
    """è·å–å¯ç”¨ç»„ä»¶åˆ—è¡¨"""
    try:
        components = {
            'parsers': ['DefaultParser'],
            'embeddings': ['LocalEmbedding'],
            'vector_stores': ['LocalVectorStore'],
            'knowledge_graphs': ['LocalKnowledgeGraph']
        }
        
        return ApiResponse(
            success=True,
            message="ç»„ä»¶åˆ—è¡¨è·å–æˆåŠŸ",
            data=components
        )
        
    except Exception as e:
        print(f"è·å–ç»„ä»¶åˆ—è¡¨å¤±è´¥: {e}")
        return ApiResponse(
            success=False,
            message="è·å–ç»„ä»¶åˆ—è¡¨å¤±è´¥",
            error=str(e)
        )

@app.delete("/api/clear", response_model=ApiResponse)
async def clear_knowledge_base():
    """æ¸…ç©ºçŸ¥è¯†åº“ï¼ˆå¼€å‘ç”¨ï¼‰"""
    try:
        if vector_store is None or knowledge_graph is None:
            raise HTTPException(status_code=500, detail="ç³»ç»Ÿæœªåˆå§‹åŒ–")
        
        # æ¸…ç©ºå‘é‡å­˜å‚¨
        if hasattr(vector_store, 'clear'):
            vector_store.clear()
        
        # æ¸…ç©ºå›¾ç»“æ„
        if hasattr(knowledge_graph, 'clear'):
            knowledge_graph.clear()
        
        return ApiResponse(
            success=True,
            message="çŸ¥è¯†åº“å·²æ¸…ç©º"
        )
        
    except Exception as e:
        print(f"æ¸…ç©ºçŸ¥è¯†åº“å¤±è´¥: {e}")
        return ApiResponse(
            success=False,
            message="æ¸…ç©ºçŸ¥è¯†åº“å¤±è´¥",
            error=str(e)
        )

async def process_file_task(task_id: str, file_path: str, original_filename: str, save_graph: bool = True, file_type: str = 'document'):
    """åå°å¤„ç†æ–‡ä»¶ä»»åŠ¡"""
    try:
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå¤„ç†ä¸­
        processing_tasks[task_id] = ProcessingStatus(
            status="processing",
            message=f"æ­£åœ¨å¤„ç†æ–‡ä»¶ {original_filename}",
            progress=10
        )
        
        # åˆ›å»ºæ–‡æ¡£è§£æå™¨
        parser = factory.create_document_parser()
        processing_tasks[task_id].progress = 30
        
        # è§£ææ–‡æ¡£
        print(f"å¼€å§‹è§£ææ–‡æ¡£: {original_filename}")
        documents = parser.parse_file(file_path)
        processing_tasks[task_id].progress = 60
        
        # æ ‡è®°æ¯ä¸ªæ–‡æ¡£çš„ç±»å‹å’ŒåŸæ–‡ä»¶å
        for doc in documents:
            if 'file_type' not in doc.metadata:
                doc.metadata['file_type'] = file_type
            if 'source_file' not in doc.metadata:
                doc.metadata['source_file'] = original_filename
        
        # æ·»åŠ åˆ°å‘é‡å­˜å‚¨
        print(f"æ·»åŠ  {len(documents)} ä¸ªæ–‡æ¡£å—åˆ°å‘é‡å­˜å‚¨")
        doc_ids = vector_store.add_documents(documents)
        processing_tasks[task_id].progress = 80
        
        # æ„å»ºçŸ¥è¯†å›¾è°±ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if save_graph and knowledge_graph:
            print("æ›´æ–°çŸ¥è¯†å›¾è°±")
            knowledge_graph.build_from_documents(documents)
        
        processing_tasks[task_id].progress = 100
        
        # å®Œæˆä»»åŠ¡
        processing_tasks[task_id] = ProcessingStatus(
            status="completed",
            message=f"æ–‡ä»¶ {original_filename} å¤„ç†å®Œæˆ",
            progress=100,
            result={
                "document_count": len(documents),
                "document_ids": doc_ids,
                "filename": original_filename
            }
        )
        
        print(f"æ–‡ä»¶å¤„ç†å®Œæˆ: {original_filename}, ç”Ÿæˆäº† {len(documents)} ä¸ªæ–‡æ¡£å—")
        
    except Exception as e:
        print(f"æ–‡ä»¶å¤„ç†å¤±è´¥: {str(e)}")
        processing_tasks[task_id] = ProcessingStatus(
            status="failed",
            message=f"æ–‡ä»¶ {original_filename} å¤„ç†å¤±è´¥",
            progress=0,
            error=str(e)
        )
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        try:
            if os.path.exists(file_path):
                os.remove(file_path)
        except:
            pass

async def process_text_task(task_id: str, content: str, title: str, save_graph: bool = True, file_type: str = 'document'):
    """åå°å¤„ç†æ–‡æœ¬ä»»åŠ¡"""
    try:
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå¤„ç†ä¸­
        processing_tasks[task_id] = ProcessingStatus(
            status="processing",
            message=f"æ­£åœ¨å¤„ç†æ–‡æœ¬: {title}",
            progress=10
        )
        
        # åˆ›å»ºæ–‡æ¡£è§£æå™¨
        parser = factory.create_document_parser()
        processing_tasks[task_id].progress = 30
        
        # åˆ›å»ºæ–‡æ¡£å¯¹è±¡
        from langchain.schema import Document as LangchainDocument
        document = LangchainDocument(
            page_content=content,
            metadata={
                "title": title or "ç”¨æˆ·æ·»åŠ çš„æ–‡æœ¬",
                "source": "user_input",
                "type": "text",
                "file_type": file_type,
                "source_file": title or "ç”¨æˆ·æ·»åŠ çš„æ–‡æœ¬"
            }
        )
        
        # åˆ†å‰²é•¿æ–‡æœ¬ï¼ˆå¦‚æœéœ€è¦ï¼‰
        documents = [document]  # ç®€å•å®ç°ï¼Œä¸åˆ†å‰²
        processing_tasks[task_id].progress = 60
        
        # æ·»åŠ åˆ°å‘é‡å­˜å‚¨
        print(f"æ·»åŠ æ–‡æœ¬åˆ°å‘é‡å­˜å‚¨: {title}")
        doc_ids = vector_store.add_documents(documents)
        processing_tasks[task_id].progress = 80
        
        # æ„å»ºçŸ¥è¯†å›¾è°±ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if save_graph and knowledge_graph:
            print("æ›´æ–°çŸ¥è¯†å›¾è°±")
            knowledge_graph.build_from_documents(documents)
        
        processing_tasks[task_id].progress = 100
        
        # å®Œæˆä»»åŠ¡
        processing_tasks[task_id] = ProcessingStatus(
            status="completed",
            message=f"æ–‡æœ¬ '{title}' å¤„ç†å®Œæˆ",
            progress=100,
            result={
                "document_count": len(documents),
                "document_ids": doc_ids,
                "title": title
            }
        )
        
        print(f"æ–‡æœ¬å¤„ç†å®Œæˆ: {title}")
        
    except Exception as e:
        print(f"æ–‡æœ¬å¤„ç†å¤±è´¥: {str(e)}")
        processing_tasks[task_id] = ProcessingStatus(
            status="failed",
            message=f"æ–‡æœ¬ '{title}' å¤„ç†å¤±è´¥",
            progress=0,
            error=str(e)
        )

@app.post("/api/upload", response_model=ApiResponse)
async def upload_content(
    background_tasks: BackgroundTasks,
    file: Optional[UploadFile] = File(None),
    content: Optional[str] = Form(None),
    title: Optional[str] = Form(None),
    file_type: Optional[str] = Form('document'),  # 'code' or 'document'
    save_graph: bool = Form(True)
):
    """
    ä¸Šä¼ æ–‡ä»¶æˆ–æ·»åŠ æ–‡æœ¬å†…å®¹åˆ°çŸ¥è¯†åº“
    
    Args:
        file: ä¸Šä¼ çš„æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
        content: æ–‡æœ¬å†…å®¹ï¼ˆå¯é€‰ï¼‰
        title: æ–‡æ¡£æ ‡é¢˜ï¼ˆå¯é€‰ï¼‰
        save_graph: æ˜¯å¦ä¿å­˜åˆ°çŸ¥è¯†å›¾è°±
        
    Returns:
        ä»»åŠ¡IDç”¨äºæŸ¥è¯¢å¤„ç†çŠ¶æ€
    """
    try:
        if vector_store is None:
            raise HTTPException(status_code=500, detail="å‘é‡å­˜å‚¨æœªåˆå§‹åŒ–")
        
        # æ£€æŸ¥æ˜¯å¦æä¾›äº†æ–‡ä»¶æˆ–æ–‡æœ¬å†…å®¹
        if not file and not content:
            return ApiResponse(
                success=False,
                message="è¯·æä¾›æ–‡ä»¶æˆ–æ–‡æœ¬å†…å®¹",
                error="å¿…é¡»ä¸Šä¼ æ–‡ä»¶æˆ–æä¾›æ–‡æœ¬å†…å®¹"
            )
        
        # ç”Ÿæˆä»»åŠ¡ID
        task_id = str(uuid.uuid4())
        
        if file:
            # å¤„ç†æ–‡ä»¶ä¸Šä¼ 
            # æ£€æŸ¥æ–‡ä»¶ç±»å‹
            allowed_extensions = ['.txt', '.md', '.pdf', '.docx', '.go', '.py', '.js', '.ts', '.java', '.cpp', '.c', '.h', '.mod', '.sum']
            file_ext = os.path.splitext(file.filename or '')[1].lower()
            if file_ext not in allowed_extensions:
                return ApiResponse(
                    success=False,
                    message=f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_ext}",
                    error=f"æ”¯æŒçš„æ ¼å¼: {', '.join(allowed_extensions)}"
                )
            
            # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
            temp_dir = tempfile.gettempdir()
            temp_filename = f"{task_id}_{file.filename}"
            temp_file_path = os.path.join(temp_dir, temp_filename)
            
            with open(temp_file_path, "wb") as buffer:
                shutil.copyfileobj(file.file, buffer)
            
            # åˆ›å»ºåˆå§‹ä»»åŠ¡çŠ¶æ€
            processing_tasks[task_id] = ProcessingStatus(
                status="processing",
                message=f"å¼€å§‹å¤„ç†æ–‡ä»¶ {file.filename}",
                progress=0
            )
            
            # æ·»åŠ åå°ä»»åŠ¡
            background_tasks.add_task(
                process_file_task,
                task_id,
                temp_file_path,
                file.filename or "unknown",
                save_graph,
                file_type  # ä¼ é€’file_type
            )
            
            return ApiResponse(
                success=True,
                message="æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼Œæ­£åœ¨åå°å¤„ç†",
                data=UploadResponse(task_id=task_id).dict()
            )
            
        else:
            # å¤„ç†æ–‡æœ¬å†…å®¹
            if not content.strip():
                return ApiResponse(
                    success=False,
                    message="æ–‡æœ¬å†…å®¹ä¸èƒ½ä¸ºç©º",
                    error="è¯·æä¾›æœ‰æ•ˆçš„æ–‡æœ¬å†…å®¹"
                )
            
            # åˆ›å»ºåˆå§‹ä»»åŠ¡çŠ¶æ€
            processing_tasks[task_id] = ProcessingStatus(
                status="processing",
                message=f"å¼€å§‹å¤„ç†æ–‡æœ¬: {title or 'ç”¨æˆ·æ–‡æœ¬'}",
                progress=0
            )
            
            # æ·»åŠ åå°ä»»åŠ¡
            background_tasks.add_task(
                process_text_task,
                task_id,
                content,
                title or "ç”¨æˆ·æ–‡æœ¬",
                save_graph,
                file_type  # ä¼ é€’file_type
            )
            
            return ApiResponse(
                success=True,
                message="æ–‡æœ¬æ·»åŠ æˆåŠŸï¼Œæ­£åœ¨åå°å¤„ç†",
                data=UploadResponse(task_id=task_id).dict()
            )
        
    except Exception as e:
        print(f"ä¸Šä¼ å¤„ç†å¤±è´¥: {str(e)}")
        return ApiResponse(
            success=False,
            message="ä¸Šä¼ å¤„ç†å¤±è´¥",
            error=str(e)
        )

@app.get("/api/upload/status/{task_id}", response_model=ApiResponse)
async def get_upload_status(task_id: str):
    """è·å–æ–‡ä»¶å¤„ç†çŠ¶æ€"""
    try:
        if task_id not in processing_tasks:
            raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
        
        status = processing_tasks[task_id]
        return ApiResponse(
            success=True,
            message="çŠ¶æ€è·å–æˆåŠŸ",
            data=status.dict()
        )
        
    except Exception as e:
        print(f"è·å–ä»»åŠ¡çŠ¶æ€å¤±è´¥: {str(e)}")
        return ApiResponse(
            success=False,
            message="è·å–ä»»åŠ¡çŠ¶æ€å¤±è´¥",
            error=str(e)
        )

@app.get("/api/graph/data", response_model=ApiResponse)
async def get_graph_data():
    """è·å–çŸ¥è¯†å›¾è°±æ•°æ®ï¼ˆç”¨äºå¯è§†åŒ–ï¼‰"""
    try:
        if knowledge_graph is None:
            raise HTTPException(status_code=500, detail="çŸ¥è¯†å›¾è°±æœªåˆå§‹åŒ–")
        
        # å¯¼å‡ºå›¾è°±æ•°æ®
        graph_data = knowledge_graph.export()
        
        return ApiResponse(
            success=True,
            message="å›¾è°±æ•°æ®è·å–æˆåŠŸ",
            data=graph_data
        )
        
    except Exception as e:
        print(f"è·å–å›¾è°±æ•°æ®å¤±è´¥: {str(e)}")
        return ApiResponse(
            success=False,
            message="è·å–å›¾è°±æ•°æ®å¤±è´¥",
            error=str(e)
        )

@app.delete("/api/graph/node/{node_id}", response_model=ApiResponse)
async def delete_graph_node(node_id: str):
    """åˆ é™¤çŸ¥è¯†å›¾è°±ä¸­çš„èŠ‚ç‚¹"""
    try:
        if knowledge_graph is None:
            raise HTTPException(status_code=500, detail="çŸ¥è¯†å›¾è°±æœªåˆå§‹åŒ–")
        
        # åˆ é™¤èŠ‚ç‚¹
        success = knowledge_graph.remove_node(node_id)
        
        if success:
            return ApiResponse(
                success=True,
                message=f"èŠ‚ç‚¹ {node_id} å·²åˆ é™¤",
                data={"node_id": node_id}
            )
        else:
            return ApiResponse(
                success=False,
                message=f"èŠ‚ç‚¹ {node_id} ä¸å­˜åœ¨æˆ–åˆ é™¤å¤±è´¥"
            )
        
    except Exception as e:
        print(f"åˆ é™¤èŠ‚ç‚¹å¤±è´¥: {str(e)}")
        return ApiResponse(
            success=False,
            message="åˆ é™¤èŠ‚ç‚¹å¤±è´¥",
            error=str(e)
        )

@app.post("/api/graph/reset", response_model=ApiResponse)
async def reset_graph():
    """é‡ç½®çŸ¥è¯†å›¾è°±"""
    try:
        if knowledge_graph is None:
            raise HTTPException(status_code=500, detail="çŸ¥è¯†å›¾è°±æœªåˆå§‹åŒ–")
        
        # æ¸…ç©ºå›¾è°±
        knowledge_graph.clear()
        
        return ApiResponse(
            success=True,
            message="çŸ¥è¯†å›¾è°±å·²é‡ç½®"
        )
        
    except Exception as e:
        print(f"é‡ç½®å›¾è°±å¤±è´¥: {str(e)}")
        return ApiResponse(
            success=False,
            message="é‡ç½®å›¾è°±å¤±è´¥",
            error=str(e)
        )

if __name__ == "__main__":
    print("ğŸš€ å¯åŠ¨çŸ¥è¯†å›¾è°± API æœåŠ¡å™¨...")
    print("ğŸ“ APIæ–‡æ¡£åœ°å€: http://localhost:8001/docs")
    print("ğŸ” å‰ç«¯åœ°å€: http://localhost:3000")
    
    uvicorn.run(
        "api_server:app",
        host="0.0.0.0",
        port=8001,
        reload=False,
        log_level="info"
    )